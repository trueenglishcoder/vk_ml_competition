{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.model_selection import train_test_split\n",
    "from catboost import Pool\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обернем все преобразования сделанные в preprocessing.ipynb в pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataframeTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, train = True):\n",
    "        self.train = train\n",
    "\n",
    "    def fit(self, df):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        # bd\n",
    "        median_age = np.median(df[(df['bd'] > 0) & (df['bd'] <= 99)]['bd'])\n",
    "        df.loc[(df['bd'] <= 0) | (df['bd'] > 99), 'bd'] = median_age\n",
    "\n",
    "        # song_length\n",
    "        song_length_age = np.median(df['song_length'])\n",
    "        df.loc[(df['song_length'] <= 0) | (df['song_length'] > 99), 'bd'] = song_length_age\n",
    "\n",
    "        # genre_ids\n",
    "        df['genre_ids'] = df['genre_ids'].fillna('-1')\n",
    "\n",
    "        df['genre_1'] = df['genre_ids'].apply(lambda x: x.split('|')[0] if len(x.split('|')) > 0 else 'NaN')\n",
    "        df['genre_2'] = df['genre_ids'].apply(lambda x: x.split('|')[1] if len(x.split('|')) > 1 else 'NaN')\n",
    "        df['genre_3'] = df['genre_ids'].apply(lambda x: x.split('|')[2] if len(x.split('|')) > 2 else 'NaN')\n",
    "\n",
    "        df['genre_ids'] = df['genre_ids'].apply(lambda x: list(map(int, x.split('|'))))\n",
    "\n",
    "        # artist_name\n",
    "        df['artist_name'] = df['artist_name'].replace('Various Artists', np.nan)\n",
    "\n",
    "        # language\n",
    "        df['language'] = df['language'].fillna(52)\n",
    "        df['language'] = df['language'].apply(lambda x: int(x))\n",
    "\n",
    "        # most common genres feature\n",
    "        most_common_genres = df.groupby('msno')['genre_ids'].agg(lambda x: pd.Series(x).explode().value_counts().head(3).index.tolist())\n",
    "        most_common_genres = most_common_genres.reset_index()\n",
    "\n",
    "        most_common_genres['most_common_genre1'] = most_common_genres['genre_ids'].apply(lambda x: x[0] if len(x) > 0 else 'NaN')\n",
    "        most_common_genres['most_common_genre2'] = most_common_genres['genre_ids'].apply(lambda x: x[1] if len(x) > 1 else 'NaN')\n",
    "        most_common_genres['most_common_genre3'] = most_common_genres['genre_ids'].apply(lambda x: x[2] if len(x) > 2 else 'NaN')\n",
    "\n",
    "        most_common_genres.drop(columns=['genre_ids'], inplace=True)\n",
    "\n",
    "        df = pd.merge(df, most_common_genres, on='msno', how='left')\n",
    "\n",
    "        # most common aritsts feature\n",
    "        most_common_artists = df.groupby('msno')['artist_name'].agg(lambda x: pd.Series(x).value_counts().head(3).index.tolist())\n",
    "        most_common_artists = most_common_artists.reset_index()\n",
    "\n",
    "        most_common_artists['most_common_artist1'] = most_common_artists['artist_name'].apply(lambda x: x[0] if len(x) > 0 else 'NaN')\n",
    "        most_common_artists['most_common_artist2'] = most_common_artists['artist_name'].apply(lambda x: x[1] if len(x) > 1 else 'NaN')\n",
    "        most_common_artists['most_common_artist3'] = most_common_artists['artist_name'].apply(lambda x: x[2] if len(x) > 2 else 'NaN')\n",
    "\n",
    "        most_common_artists.drop(columns=['artist_name'], inplace=True)\n",
    "\n",
    "        df = pd.merge(df, most_common_artists, on='msno', how='left')\n",
    "\n",
    "        # most common language feature\n",
    "        most_common_language = df.groupby('msno')['language'].agg(lambda x: pd.Series(x).value_counts().head(3).index.tolist())\n",
    "        most_common_language = most_common_language.reset_index()\n",
    "\n",
    "        most_common_language['most_common_language1'] = most_common_language['language'].apply(lambda x: x[0] if len(x) > 0 else 'NaN')\n",
    "        most_common_language['most_common_language2'] = most_common_language['language'].apply(lambda x: x[1] if len(x) > 1 else 'NaN')\n",
    "        most_common_language['most_common_language3'] = most_common_language['language'].apply(lambda x: x[2] if len(x) > 2 else 'NaN')\n",
    "\n",
    "        most_common_language.drop(columns=['language'], inplace=True)\n",
    "\n",
    "        df = pd.merge(df, most_common_language, on='msno', how='left')\n",
    "\n",
    "        columns_to_keep = ['msno', 'song_id', 'source_system_tab', 'source_screen_name', \n",
    "                   'source_type', 'city', 'bd', 'gender',\n",
    "                   'genre_1', 'genre_2', 'genre_3',\n",
    "                   'most_common_genre1', 'most_common_genre2', 'most_common_genre3',\n",
    "                   'most_common_artist1', 'most_common_artist2', 'most_common_artist3',\n",
    "                   'most_common_language1', 'most_common_language2', 'most_common_language3',\n",
    "                   'song_length', 'artist_name',\n",
    "                   'language', 'name']\n",
    "        \n",
    "        if self.train:\n",
    "            columns_to_keep = columns_to_keep + ['target']\n",
    "        \n",
    "        df = df[columns_to_keep]\n",
    "\n",
    "\n",
    "        df.fillna('NaN', inplace=True)\n",
    "        return df\n",
    "\n",
    "class CatBoostPoolTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, train = True):\n",
    "        self.train = train\n",
    "    \n",
    "    def fit(self, df):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, df):\n",
    "        cat_features = ['msno', 'song_id', 'source_system_tab', 'source_screen_name', \n",
    "                        'source_type', 'city', 'gender',\n",
    "                        'genre_1', 'genre_2', 'genre_3',\n",
    "                        'most_common_genre1', 'most_common_genre2', 'most_common_genre3',\n",
    "                        'most_common_artist1', 'most_common_artist2', 'most_common_artist3',\n",
    "                        'most_common_language1', 'most_common_language2', 'most_common_language3',\n",
    "                        'artist_name',\n",
    "                        'language', 'name']\n",
    "        if self.train:\n",
    "            X = df.drop(columns=['target'])\n",
    "            y = df['target']\n",
    "        else:\n",
    "            X = df\n",
    "\n",
    "        if self.train:\n",
    "            X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "\n",
    "            train_group_id = X_train['msno'].factorize()[0]\n",
    "            train_sorted_indices = train_group_id.argsort()\n",
    "\n",
    "            train_pool = Pool(X_train.iloc[train_sorted_indices].reset_index(drop=True),\n",
    "                            label = y_train.iloc[train_sorted_indices].reset_index(drop=True),\n",
    "                            cat_features=cat_features, \n",
    "                            group_id=train_group_id[train_sorted_indices])\n",
    "            \n",
    "            val_group_id = X_val['msno'].factorize()[0]\n",
    "            val_sorted_indices = val_group_id.argsort()\n",
    "            \n",
    "            val_pool = Pool(X_val.iloc[val_sorted_indices].reset_index(drop=True),\n",
    "                            label = y_val.iloc[val_sorted_indices].reset_index(drop=True),\n",
    "                            cat_features=cat_features, \n",
    "                            group_id=val_group_id[val_sorted_indices])\n",
    "            return train_pool, val_pool\n",
    "\n",
    "        else:\n",
    "            group_id = X['msno'].factorize()[0]\n",
    "            sorted_indices = group_id.argsort()\n",
    "            test_pool = Pool(X.iloc[sorted_indices].reset_index(drop=True),\n",
    "                            cat_features=cat_features, \n",
    "                            group_id=group_id[sorted_indices])\n",
    "            return test_pool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "members_df = pd.read_csv('members.csv')\n",
    "songs_df = pd.read_csv('songs.csv')\n",
    "songs_extra_info_df = pd.read_csv('song_extra_info.csv')\n",
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "sample_submission_df = pd.read_csv('sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_song_df = pd.merge(songs_df, songs_extra_info_df, on = 'song_id', how = 'outer')\n",
    "full_train_df = pd.merge(train_df, members_df, on = 'msno', how = 'left')\n",
    "full_train_df = pd.merge(full_train_df, full_song_df, on = 'song_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pipeline = Pipeline([\n",
    "    ('dataframe_transformer', DataframeTransformer()),\n",
    "    ('catboost_pool_transformer', CatBoostPoolTransformer()),\n",
    "])\n",
    "\n",
    "test_pipeline = Pipeline([\n",
    "    ('dataframe_transformer', DataframeTransformer(train = False)),\n",
    "    ('catboost_pool_transformer', CatBoostPoolTransformer(train = False)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saaky\\AppData\\Local\\Temp\\ipykernel_14396\\2373368957.py:84: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'NaN' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.fillna('NaN', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "train_pool, val_pool = train_pipeline.fit_transform(full_train_df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_test_df = pd.merge(test_df, members_df, on = 'msno', how = 'left')\n",
    "full_test_df = pd.merge(full_test_df, full_song_df, on = 'song_id', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\saaky\\AppData\\Local\\Temp\\ipykernel_14396\\2373368957.py:84: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value 'NaN' has dtype incompatible with float64, please explicitly cast to a compatible dtype first.\n",
      "  df.fillna('NaN', inplace=True)\n"
     ]
    }
   ],
   "source": [
    "test_pool = test_pipeline.fit_transform(full_test_df.copy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Берем стандартный для такого рода задач CatBoostClassifier с испольованием метрики указанной в задании. Затем предсказываем вероятности классов, чтобы получить ранжирование по трекам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "catboost_model = CatBoostClassifier(iterations=1000,\n",
    "                                    depth=2,\n",
    "                                    early_stopping_rounds=10,\n",
    "                                    loss_function='CrossEntropy',\n",
    "                                    eval_metric='NDCG:top=20',\n",
    "                                    verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x1df8f2a6490>"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "catboost_model.fit(train_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_result = catboost_model.eval_metrics(val_pool, metrics=['NDCG:top=20'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG@20 на валидационном датасете = 0.853\n"
     ]
    }
   ],
   "source": [
    "print('NDCG@20 на валидационном датасете = {:0.3f}'.format(eval_result['NDCG:top=20;type=Base'][-1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = catboost_model.predict_proba(test_pool)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.66133014 0.64446783 0.67013436 ... 0.75501128 0.75997615 0.81831449]\n"
     ]
    }
   ],
   "source": [
    "print(pred[:,0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
